{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сегментация медицинских изображений с локалайзера компьютерного томографа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имортированые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pydicom.datadict import DicomDictionary, keyword_dict\n",
    "from pydicom.pixel_data_handlers.numpy_handler import pack_bits\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разметка изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача разметки данных изображений заключается в том, чтобы отметить на снимке один (или несколько) из пяти отделов человеческого тела. Размечатся изображеня будут для пяти типов исследования для каждого отдела соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Необходимо указать тип иссследования:\n",
    "     * Определение головы на снимке: head_segmentation\n",
    "     * Определение шейного отдела на снимке: neck_segmentation\n",
    "     * Определение грудной клетки на снимке: chest_segmentation\n",
    "     * Определение брюшной полости на снимке: abdomen_segmentation\n",
    "     * Определение области малого таза на снимке: pelvis_segmentation\n",
    "\"\"\"\n",
    "STUDY_TYPE = 'head_segmentation'\n",
    "\n",
    "BODY_PART_NAME = ''\n",
    "if STUDY_TYPE == 'head_segmentation':\n",
    "    BODY_PART_NAME = 'Head'\n",
    "elif STUDY_TYPE == 'neck_segmentation':\n",
    "    BODY_PART_NAME = 'Neck'\n",
    "elif STUDY_TYPE == 'chest_segmentation':\n",
    "    BODY_PART_NAME = 'Chest'\n",
    "elif STUDY_TYPE == 'abdomen_segmentation':\n",
    "    BODY_PART_NAME = 'Abdomen'\n",
    "elif STUDY_TYPE == 'pelvis_segmentation':\n",
    "    BODY_PART_NAME = 'Pelvis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мной использован следующий подход. \n",
    "\n",
    "1. Загружается массив изображений, которые необходимо разметить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    all_img = [pydicom.read_file(path + '/' + i) for i in os.listdir(path)]\n",
    "    return all_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Получаются значения каждого воксела изображения и стандартизуются:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voxels(img):\n",
    "    image1 = np.stack(img.pixel_array)\n",
    "    image1 = image1.astype(np.int16)\n",
    "    image1[image1 == -2000] = 0\n",
    "    intercept = img.RescaleIntercept\n",
    "    slope = img.RescaleSlope\n",
    "    if slope != 1:\n",
    "        image1 = slope * image1.astype(np.float64)\n",
    "        image1 = image1.astype(np.int16)\n",
    "    image1 += np.int16(intercept)\n",
    "    return np.array(image1, dtype=np.int16)\n",
    "\n",
    "def standardize_voxel_values(img):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = img-mean\n",
    "    img = img/std\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_standardize_image(img, title='Standardized image'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создается ограничительная рамка с интересующим отделом тела, по введенным противоположным координатам этой рамки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demo_box(img, point_x_beg, point_y_beg, point_x_end, point_y_end):\n",
    "    img[point_y_beg, point_x_beg:point_x_end] = 1\n",
    "    img[point_y_end, point_x_beg:point_x_end] = 1\n",
    "    img[point_y_beg:point_y_end, point_x_beg] = 1\n",
    "    img[point_y_beg:point_y_end, point_x_end] = 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Если данная рамка удовлетворяет нас, то закрепляем результат, создая бинарную рамку, которая будет использованя в виде `overlay array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_box(img, point_x_beg, point_y_beg, point_x_end, point_y_end):\n",
    "    bound_box = img\n",
    "    for i in range(len(bound_box)):\n",
    "        for j in range(len(bound_box[i])):\n",
    "            bound_box[i][j] = 0\n",
    "\n",
    "    bound_box[point_y_beg, point_x_beg:point_x_end] = 1\n",
    "    bound_box[point_y_end, point_x_beg:point_x_end] = 1\n",
    "    bound_box[point_y_beg:point_y_end, point_x_beg] = 1\n",
    "    bound_box[point_y_beg:point_y_end, point_x_end] = 1\n",
    "    return bound_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Накладываем данную рамку на выбранный снимок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_overlay(img, area, array):\n",
    "    groups = {\n",
    "        'Head': 0x6000,\n",
    "        'Neck': 0x6002,\n",
    "        'Chest': 0x6004,\n",
    "        'Abdomen': 0x6006,\n",
    "        'Pelvis': 0x6008,\n",
    "    }\n",
    "\n",
    "    string = area + ': Overlay Rows'\n",
    "\n",
    "    new_dict_items = {\n",
    "        (groups[area], 0x0010): ('US', '1', string, '', 'OverlayRows'),\n",
    "        (groups[area], 0x0011): ('US', '1', area + \": Overlay Columns\", '', 'OverlayColumns'),\n",
    "        (groups[area], 0x0015): ('IS', '1', area + \": Number of Frames in Overlay\", '', 'NumberFrames'),\n",
    "        (groups[area], 0x0022): ('LO', '1', area + \": Overlay Description \", '', 'OverlayDescription'),\n",
    "        (groups[area], 0x0040): ('CS', '1', area + \": Overlay Type\", '', 'OverlayType'),\n",
    "        (groups[area], 0x0050): ('SS', '2', area + \": Overlay Origin\", '', 'OverlayOrigin'),\n",
    "        (groups[area], 0x0051): ('US', '1', area + \": Image Frame Origin \", '', 'ImageFrameOrigin'),\n",
    "        (groups[area], 0x0100): ('US', '1', area + \": Overlay Bits Allocated\", '', 'OverlayBitsAllocated'),\n",
    "        (groups[area], 0x0102): ('US', '1', area + \": Overlay Bit Position\", '', 'OverlayBitPosition'),\n",
    "        (groups[area], 0x3000): ('OW', '1', area + \": Overlay Data\", '', 'OverlayData'),\n",
    "    }\n",
    "\n",
    "    DicomDictionary.update(new_dict_items)\n",
    "    new_names_dict = dict([(val[4], tag) for tag, val in new_dict_items.items()])\n",
    "    keyword_dict.update(new_names_dict)\n",
    "    row_count, col_count = array.shape\n",
    "    img.OverlayRows = row_count\n",
    "    img.OverlayColumns = col_count\n",
    "    img.NumberFrames = 1\n",
    "    img.OverlayDescription = area\n",
    "    img.OverlayType = 'G'\n",
    "    img.OverlayOrigin = [1, 1]\n",
    "    img.ImageFrameOrigin = 1\n",
    "    img.OverlayBitsAllocated = 1\n",
    "    img.OverlayBitPosition = 0\n",
    "    array_new = np.reshape(array, array.size)\n",
    "    packed_bytes = pack_bits(array_new)\n",
    "\n",
    "    if len(packed_bytes) % 2:\n",
    "        packed_bytes += b'\\x00'\n",
    "\n",
    "    img.OverlayData = packed_bytes\n",
    "    img[groups[area], 0x3000].VR = 'OW'\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Пример применения описанного выше подхода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем пути для исходных и выходных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/computer/SCIENTIFIC_WORK/segmentation_medical_images/ct_locator_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_with = 'Data/' + STUDY_TYPE + '/' + BODY_PART_NAME + '/'\n",
    "output_path_without = 'Data/' + STUDY_TYPE + '/Other/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем номер интересующего снимка (пусть для примера это будет первый элемент массива снимков):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter image number:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('Enter image number:')\n",
    "number = int(input())\n",
    "image = images[number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим полученное изображение в дополнительном окне и отметим (наведением курсора в области изображения) противоположные вершины ограничительной рамки для выбранного отдела: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "image_vox = get_voxels(image)\n",
    "image_std = standardize_voxel_values(image_vox)\n",
    "show_standardize_image(image_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательно введем координаты даные координаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the coordinates of the first point of the bounding box:\n",
      "100\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print('Enter the coordinates of the first point of the bounding box:')\n",
    "beg_point_x = int(input())\n",
    "beg_point_y = int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the coordinates of the end point of the bounding box:\n",
      "350\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "print('Enter the coordinates of the end point of the bounding box:')\n",
    "end_point_x = int(input())\n",
    "end_point_y = int(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим и выведем на экран, полученную рамку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_st = create_demo_box(image_std, beg_point_x, beg_point_y, end_point_x, end_point_y)\n",
    "show_standardize_image(image_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедившись в корректности рамки, создаем ее бинарный аналог:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_for_box = image_std\n",
    "bounding_box = create_box(image_for_box, beg_point_x, beg_point_y, end_point_x, end_point_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим рамку к исходному изображению, аннотируем ее наименованием интересующего отдела и выведем метаданные `.dicom`-файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the marked object: (Head, Neck, Chest, Abdomen, Pelvis)\n",
      "Head\n",
      "Dataset.file_meta -------------------------------\n",
      "(0002, 0000) File Meta Information Group Length  UL: 190\n",
      "(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n",
      "(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n",
      "(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.113704.1.111.4580.1489087675.28499\n",
      "(0002, 0010) Transfer Syntax UID                 UI: JPEG Lossless, Non-Hierarchical (Process 14)\n",
      "(0002, 0012) Implementation Class UID            UI: 1.2.826.0.1.3680043.2.135.1066.101\n",
      "(0002, 0013) Implementation Version Name         SH: '1.4.16/OTHER'\n",
      "-------------------------------------------------\n",
      "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008, 0008) Image Type                          CS: ['ORIGINAL', 'PRIMARY', 'LOCALIZER']\n",
      "(0008, 0012) Instance Creation Date              DA: '19800101'\n",
      "(0008, 0013) Instance Creation Time              TM: '555555'\n",
      "(0008, 0016) SOP Class UID                       UI: CT Image Storage\n",
      "(0008, 0018) SOP Instance UID                    UI: 1.2.840.113704.1.111.4580.1489087675.28499\n",
      "(0008, 0020) Study Date                          DA: '19800101'\n",
      "(0008, 0022) Acquisition Date                    DA: '19800101'\n",
      "(0008, 0023) Content Date                        DA: '19800101'\n",
      "(0008, 002a) Acquisition DateTime                DT: ''\n",
      "(0008, 0030) Study Time                          TM: '555555'\n",
      "(0008, 0032) Acquisition Time                    TM: '555555'\n",
      "(0008, 0033) Content Time                        TM: '555555'\n",
      "(0008, 0050) Accession Number                    SH: ''\n",
      "(0008, 0060) Modality                            CS: 'CT'\n",
      "(0008, 0070) Manufacturer                        LO: 'unknown'\n",
      "(0008, 0080) Institution Name                    LO: 'unknown'\n",
      "(0008, 0081) Institution Address                 ST: 'unknown'\n",
      "(0008, 0090) Referring Physician's Name          PN: ''\n",
      "(0008, 1010) Station Name                        SH: 'unknown'\n",
      "(0008, 1030) Study Description                   LO: ''\n",
      "(0008, 103e) Series Description                  LO: ''\n",
      "(0008, 1040) Institutional Department Name       LO: 'unknown'\n",
      "(0008, 1070) Operators' Name                     PN: ''\n",
      "(0008, 1090) Manufacturer's Model Name           LO: 'unknown'\n",
      "(0010, 0010) Patient's Name                      PN: 'unknown'\n",
      "(0010, 0020) Patient ID                          LO: '1050'\n",
      "(0010, 0030) Patient's Birth Date                DA: ''\n",
      "(0010, 0040) Patient's Sex                       CS: ''\n",
      "(0010, 1010) Patient's Age                       AS: ''\n",
      "(0010, 2000) Medical Alerts                      LO: ''\n",
      "(0018, 0022) Scan Options                        CS: 'SURVIEW'\n",
      "(0018, 0050) Slice Thickness                     DS: \"0.625\"\n",
      "(0018, 0060) KVP                                 DS: \"120.0\"\n",
      "(0018, 0090) Data Collection Diameter            DS: \"500.0\"\n",
      "(0018, 1020) Software Versions                   LO: '3.5.7'\n",
      "(0018, 1030) Protocol Name                       LO: ''\n",
      "(0018, 1100) Reconstruction Diameter             DS: \"500.0\"\n",
      "(0018, 1120) Gantry/Detector Tilt                DS: \"0.0\"\n",
      "(0018, 1130) Table Height                        DS: \"86.0\"\n",
      "(0018, 1140) Rotation Direction                  CS: 'CW'\n",
      "(0018, 1141) Angular Position                    DS: \"90.0\"\n",
      "(0018, 1143) Scan Arc                            DS: \"90.0\"\n",
      "(0018, 1150) Exposure Time                       IS: \"4531\"\n",
      "(0018, 1151) X-Ray Tube Current                  IS: \"30\"\n",
      "(0018, 1160) Filter Type                         SH: 'D'\n",
      "(0018, 5100) Patient Position                    CS: 'HFS'\n",
      "(0018, 9323) Exposure Modulation Type            CS: 'NONE'\n",
      "(0018, 9345) CTDIvol                             FD: 0.168\n",
      "(0020, 000d) Study Instance UID                  UI: 1.2.840.113704.1.111.4240.1489085933.55\n",
      "(0020, 000e) Series Instance UID                 UI: 1.2.840.113704.1.111.7244.1489087648.3\n",
      "(0020, 0010) Study ID                            SH: '1050'\n",
      "(0020, 0011) Series Number                       IS: \"1\"\n",
      "(0020, 0012) Acquisition Number                  IS: None\n",
      "(0020, 0013) Instance Number                     IS: \"1\"\n",
      "(0020, 0032) Image Position (Patient)            DS: [0, -81, 210.618774]\n",
      "(0020, 0037) Image Orientation (Patient)         DS: [0, 1, 0, 0, 0, -1]\n",
      "(0020, 0052) Frame of Reference UID              UI: 1.2.840.113704.1.111.7244.1489087648.4\n",
      "(0020, 0060) Laterality                          CS: ''\n",
      "(0020, 1040) Position Reference Indicator        LO: ''\n",
      "(0020, 1041) Slice Location                      DS: \"-238.6\"\n",
      "(0020, 4000) Image Comments                      LT: ''\n",
      "(0028, 0002) Samples per Pixel                   US: 1\n",
      "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
      "(0028, 0010) Rows                                US: 460\n",
      "(0028, 0011) Columns                             US: 512\n",
      "(0028, 0030) Pixel Spacing                       DS: [0.9765625, 0.9765625]\n",
      "(0028, 0100) Bits Allocated                      US: 16\n",
      "(0028, 0101) Bits Stored                         US: 12\n",
      "(0028, 0102) High Bit                            US: 11\n",
      "(0028, 0103) Pixel Representation                US: 0\n",
      "(0028, 1050) Window Center                       DS: [00020, 00020]\n",
      "(0028, 1051) Window Width                        DS: [01500, 01500]\n",
      "(0028, 1052) Rescale Intercept                   DS: \"-1024.0\"\n",
      "(0028, 1053) Rescale Slope                       DS: \"1.0\"\n",
      "(0032, 1070) Requested Contrast Agent            LO: ''\n",
      "(0040, 0012) Pre-Medication                      LO: ''\n",
      "(0040, 0253) Performed Procedure Step ID         SH: '1820344'\n",
      "(6000, 0010) Overlay Rows                        US: 460\n",
      "(6000, 0011) Overlay Columns                     US: 512\n",
      "(6000, 0015) Number of Frames in Overlay         IS: \"1\"\n",
      "(6000, 0022) Overlay Description                 LO: 'Head'\n",
      "(6000, 0040) Overlay Type                        CS: 'G'\n",
      "(6000, 0050) Overlay Origin                      SS: [1, 1]\n",
      "(6000, 0051) Image Frame Origin                  US: 1\n",
      "(6000, 0100) Overlay Bits Allocated              US: 1\n",
      "(6000, 0102) Overlay Bit Position                US: 0\n",
      "(6000, 3000) Overlay Data                        OW: Array of 29440 elements\n",
      "(7fe0, 0010) Pixel Data                          OW: Array of 222440 elements\n"
     ]
    }
   ],
   "source": [
    "print('Enter the name of the marked object: (Head, Neck, Chest, Abdomen, Pelvis)')\n",
    "part_name = input()\n",
    "image = add_overlay(image, part_name, bounding_box)\n",
    "\n",
    "if part_name == 'Head':\n",
    "    image.save_as(output_path_with + 'image_' + str(number) + '.dcm')\n",
    "else:\n",
    "    image.save_as(output_path_without + 'image_' + str(number) + '.dcm')\n",
    "\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Использование скрипта для разметки\n",
    "\n",
    "Для разметки изображений с помощью предложенного метода, предлагаю воспользоваться скриптом [labeling.py](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/labeling.py).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание потоков с данными для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве входных данных для обучения модели классификатора отделов человеческого тела со снимков локалайзера компьютерного томографа дудут использоваться два потока байтов: поток признаков, и поток соответствующих значений целефой функции (наименование определеного отдела тела). Для этого используется алгоритм сериализации объектов `Python` модуля `pickle`.\n",
    "\n",
    "Для создания байтовых потоков предлагаю воспользоваться скриптом [loading_data.py](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/loading_data.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель распознования интересующего отдела на снимке на основе сверточной нейронной сети (СНС)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала нейбходимо выбрать тип исследования для поиска интересующего отдела на снимке из предложенного набора:\n",
    "* head_segmentation\n",
    "* neck_segmentation\n",
    "* chest_segmentation\n",
    "* abdomen_segmentation\n",
    "* pelvis_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_segmentation\n"
     ]
    }
   ],
   "source": [
    "STUDY_TYPE = str(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее загрузить подготовленные потоки для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_in = open('Streams/' + STUDY_TYPE + '/X.pickle', 'rb')\n",
    "X = pickle.load(stream_in)\n",
    "\n",
    "stream_in = open('Streams/' + STUDY_TYPE + '/y.pickle', 'rb')\n",
    "y = pickle.load(stream_in)\n",
    "\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввести оптимальные параметры для обучаемой модели: \n",
    "\n",
    "*(Для поиска оптимальных параметров для ваших данных и соответствующего типа исследования предлагаю воспользоваться скриптом* [optimizing_models.py](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/optimizing_models.py) *)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "DENSE_LAYERS = 0\n",
    "LAYER_SIZE = 256\n",
    "CONV_LAYERS = 3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель будет выглядить следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples, validate on 2 samples\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 3s 2s/sample - loss: 0.6516 - accuracy: 1.0000 - val_loss: 4.3096 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 176ms/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 11.8746 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 168ms/sample - loss: 1.5379e-07 - accuracy: 1.0000 - val_loss: 22.2461 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 164ms/sample - loss: 3.1727e-13 - accuracy: 1.0000 - val_loss: 34.5782 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 164ms/sample - loss: 5.6451e-20 - accuracy: 1.0000 - val_loss: 48.2162 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(LAYER_SIZE, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "for layer in range(CONV_LAYERS - 1):\n",
    "    model.add(Conv2D(LAYER_SIZE, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "for _ in range(DENSE_LAYERS):\n",
    "    model.add(Dense(LAYER_SIZE))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не буду сохранять данную модель. В репозитории для примера присутствует уже обученная мною модель по определению головы на снимках с локалайзера на приемлемом количестве снимков для проверки подхода воспользуюсь ей.\n",
    "\n",
    "#### Для создания же новой модели, с описанной выше архитектурой, предлагаю воспользоваться скриптом [cnn_model.py](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/cnn_model.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование обученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обученных моделей пердоставлена отдельная директория [Models](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/tree/master/Models). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " В репозиторий уже добавлена обученная модель для определения головы на снимке. Обучена данная модель на 140 снимках тренеровочной выборки и 60 вылидационной. Ее графики точности и функции потерь имеют следующий вид: \n",
    " \n",
    " ![Изображение](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/Figures/graph.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ипользования этой или других моделей предлагаю воспользоваться скриптом [prediction.py](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/prediction.py).\n",
    "\n",
    " ![Изображение](https://github.com/AlexeyPopov1997/MedicalImagesSegmentation/blob/master/Figures/prediction%20testing.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_img_segmentation",
   "language": "python",
   "name": "med_img_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
